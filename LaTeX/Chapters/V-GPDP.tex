\chapter[Modelo GPDP para regresi\'on sobre cuantiles]{Modelo GPDP para regresi\'on sobre cuantiles}

\section{Definici\'on}

Despu\'es de analizar la introducci\'on de componentes no param\'etricos en las distribuciones, tanto de $f_p$, como de $\varepsilon_p$, a continuaci\'on se enunciar\'a el modelo central de esta tesis, con sus especificaciones correspondientes.

A partir de este punto, a dicho modelo se le denominar\'a \textbf{Modelo GPDP} (por las siglas en ingl\'es de procesos Gaussianos y procesos de Dirichlet).

Sea $\{(y_i,x_i)|i=1,...,m\}$ el conjunto de observaciones de la variable de respuesta y sus respectivas covariables, cuya relaci\'on se supone como
\begin{equation*}
    y = f_p(x) + {\varepsilon_p},
\end{equation*}
donde $f_p: \mathbb{R}^n \times \mathbb{R}$ es la funci\'on cuantil y ${\varepsilon_p} \in \mathbb{R}$ es el error aleatorio, ambos desconocidos.

Para reflejar la incertidumbre y el conocimiento previo del modelador, se supone a $f_p \sim \mathcal{GP}(m,k)$, con funci\'on de medias $m$ dada por el modelador y funci\'on de covarianza $k$ del tipo 2-\textit{exponencial}, con par\'ametro de rango fijo $\tau = 1$. Es decir,
\begin{equation*}
    k(x_i, x_j|\lambda) = \lambda \text{ } exp\{-\norm{x_i - x_j}_2\},
\end{equation*}
con $\lambda \sim GI(c_\lambda,d_\lambda)$, siendo $c_\lambda$ y $d_\lambda$ los par\'ametros de forma y escala, respectivamente, de una \textit{Gamma-Inversa}, mismos que deber\'an ser elegidos por el modelador. 

La raz\'on para fijar $\tau = 1$ es para simplificar el proceso computacional de inferencia que se ver\'a en la siguiente secci\'on, pero bien podr\'ia tambi\'en tener una distribuci\'on inicial que refleje la incertidumbre acerca de su valor.

En cuanto a la distribuci\'on inicial de $\varepsilon_p$, se supondr\'a un modelo de mezclas infinitas de Dirichlet, cuya distribuci\'on media $H$ del proceso de Dirichlet ser\'a una \textit{Gamma-Inversa}, con par\'ametros de forma $c_{DP}$ y escala $d_{DP}$, elegidos por el investigador.

En resumen, el Modelo GPDP queda descrito de la siguiente forma:
\begin{equation*}
\begin{aligned}
    y_i| f_p(x_i), z_i, \sigma_k^* &\sim AL_p({\varepsilon_p}_i = y_i - f_p(x_i) | \sigma_{z_i}), \\
    f_p|m, k, \lambda &\sim \mathcal{GP}(m,k(\lambda)|\lambda), \\
    \lambda &\sim GI(c_\lambda,d_\lambda), \\
    z_i | \pi &\sim Mult_\infty(\pi), \\
    \pi | \alpha &\sim GEM(\alpha), \\
    \sigma_k^* | c_{DP}, d_{DP} &\sim GI(\sigma_k|c_{DP}, d_{DP}),\\
    k(x_i, x_j | \lambda) &= \lambda \text{ } exp\{-\norm{x_i - x_j}_2\}.
\end{aligned}
\end{equation*}

\section{Inferencia con el simulador de Gibbs}

Dado que el modelo descrito no es conjugado, las distribuciones posteriores tienen que ser aproximadas mediante m\'etodos computacionales. Para hacer esto, se puede hacer uso de algoritmos MCMC (Markov chain Monte Carlo), y particularmente del simulador de Gibbs. \footnote{En caso de que el lector no est\'e familiarizado con este tipo de algoritmos, puede consultar una breve descripci\'on de ellos en el \autoref{chap:MCMC}.}

En este orden de ideas, a continuaci\'on se detallan las distribuciones condicionales posteriores de los par\'ametros del modelo, as\'i como la inclusi\'on de algunas variables latentes para permitir el funcionamiento del algoritmo. Es oportuno recordar que dichas distribuciones posteriores resultan de multiplicar la verosimilitud por la probabilidad inicial, como se revis\'o en el cap\'itulo 2 de este trabajo.

Antes de correr los algoritmos, usualmente resulta conveniente estandarizar los datos. En primer lugar, para que la estructura de covarianza tenga más sentido, ya que la escala de las covariables afectaría la correlación que existe entre los datos, al depender esta de la distancia entre ellas. Además, estandarizar los datos suele mejorar el rendimiento computacional de este tipo de algoritmos. Asimismo, vuelve m\'as sencillo definir el valor inicial de los hiper-par\'ametros, como se detallar\'a m\'as adelante.

\subsection{Actualizaci\'on del error}

Recordando que los centros de masa y los pesos de un proceso de Dirichlet son independientes, pueden ser actualizados por separado, con el inconveniente de que hay un n\'umero infinito de par\'ametros que actualizar. Para resolverlo, se utilizará el algoritmo de truncamiento del \textit{slice sampling}, propuesto por \cite{Kalli_Slice}, y adaptado para el modelo propuesto en esta tesis. A grandes rasgos consiste en truncar las posibles subpoblaciones a un número finito, el cual se actualizar\'a de forma din\'amica, de acuerdo a lo que vaya aprendiendo de los datos. 

Sea $\xi_1,\xi_2,\xi_3,...$ una secuencia positiva, generalmente elegida de forma determinista y decreciente. Sea $N$ una variable aleatoria con soporte en los n\'umeros naturales, una variable auxiliar incorporada al modelo.

\subsubsection{Actualizaci\'on de los centros de masa}

Para cada $k \in \{1,2,...,N\}$, se obtiene que 
\begin{equation*}
\begin{gathered}
    \sigma_k | \{{\varepsilon_p}_i, z_i | z_i = k\}, c, d \sim GI(\bar{c}_{DP}, \bar{d}_{DP}),\\
    \bar{c}_{DP} = c_{DP} + |\{i| z_i = k\}|, \\
    \bar{d}_{DP} = d_{DP} 
    + p \left[\sum_{\{i| z_i = k,\text{ }{\varepsilon_p}_i \geq 0\}} {\varepsilon_p}_i\right]
    + (1-p) \left[\sum_{\{i| \text{ } z_i = k,\text{ }{\varepsilon_p}_i < 0\}}  -{\varepsilon_p}_i\right].
\end{gathered}
\end{equation*}

\subsubsection{Actualizaci\'on de los pesos}

Sea $\bar{\pi}_k = \beta_k \prod_{j=1}^{k-1}(1 - \beta_j)$, de modo que para cada $k \in \{1,2,...,N\}$, la distribuci\'on condicional posterior de $\beta_k$ es
\begin{equation*}
\begin{aligned}
    \beta_k|\{z_i\}, a,b &\sim Beta(\bar{a}, \bar{b}), \\
    \bar{a} &= 1 + |\{i|z_i = k\}|, \\
    \bar{b} &= \alpha + |\{i|z_i > k\}|.
\end{aligned}
\end{equation*}

Dado que existe un n\'umero finito de posibles subpoblaciones, ya no se sigue propiamente la distribuci\'on $GEM$, sino un truncamiento de ella hasta la $N$-\'esima subpoblaci\'on. Posteriormente se realiza un reescalamiento de las probabilidades para que sumen 1. Es decir, se calcula
\begin{equation*}
\begin{aligned}
    \pi_k = \frac{\bar{\pi_k}}{\sum_{j=1}^N \bar{\pi_j}}
\end{aligned}
\end{equation*}

\subsubsection{Actualizaci\'on de las clases y variables de truncamiento}

Siguiendo el algoritmo de \cite{Kalli_Slice}, para cada observaci\'on $i \in \{1,...,m\}$, se obtiene
\begin{equation*}
\begin{aligned}
   u_i \sim U(0, \xi_{z_i}),
\end{aligned}
\end{equation*}
valor que se utiliza para actualizar la probabilidad de pertenencia a cada clase de la siguiente forma. Para cada $k \in \{1,2,...,N\}$,
\begin{equation*}
\begin{aligned}
   P(z_i = k| {\varepsilon_p}_i, \pi_k, \sigma_k)
   \propto
   \mathds{1}(u_i < \xi_k)
   \cdot
   \frac{\pi_k}{\xi_k}
   \cdot
   AL_p({\varepsilon_p}_i | \sigma_k).
\end{aligned}
\end{equation*}

Posteriormente se actualiza
\begin{equation*}
\begin{aligned}
   N = \max\{
    N_i|N_i=\max\{j|\xi_j > u_i\}, 
    i \in \{1,...,m\}
   \}.
\end{aligned}
\end{equation*}

\subsection{Actualizaci\'on de la tendencia}

Se define la siguiente variable aleatoria auxiliar, con la finalidad de anticipar si $\varepsilon_p = y - f_p(x)$ ser\'a positiva o negativa, y as\'i simplificar el c\'alculo de la actualizaci\'on de $f_p$.
\begin{equation*}
\begin{aligned}
    b_i | p, \sigma_i &\sim 
    \begin{cases}
        \frac{p}{\sigma_i} &prob = P({\varepsilon_p}_i \geq 0) = 1-p\\
        -\frac{1-p}{\sigma_i} &prob = P({\varepsilon_p}_i < 0) = p
    \end{cases},\\
\end{aligned}
\end{equation*}
de forma que $b = [b_1,...,b_m]^T$. 

\subsubsection{Actualizaci\'on de $\bm{f_p(X)}$}

Es pertinente recordar que la funci\'on de densidad de una observaci\'on $y_i$, debido a que sigue la distribuci\'on asim\'etrica de Laplace, se escribe
\begin{equation*}
\begin{aligned}
    P(y_i | f_p(x_i),\sigma_i) = 
    \frac{p(1-p)}{\sigma_i}
    exp \left\{-\rho_p
        \left(
            \frac{y_i-f_p(x_i)}{\sigma_i}
        \right)
    \right\}
    \mathds{1}_{(-\infty,\infty)}.
\end{aligned}
\end{equation*}

Una vez calculada la variable auxiliar $b$ que reci\'en se acaba de definir, dicha densidad se puede expresar de forma condicional como
\begin{gather*}
    P(y_i | f_p(x_i),\sigma_i,b_i) \propto
    \begin{cases}
        exp \left\{
            \frac{-p(y_i-f_p(x_i))}{\sigma_i}
        \right\} \mathds{1}_{\{y_i - f(x_i) \geq 0\}} 
        &\text{si } b_i > 0\\
        exp \left\{
            \frac{(1-p)(y_i-f_p(x_i))}{\sigma_i}
        \right\} \mathds{1}_{\{y_i - f(x_i) < 0\}} 
        &\text{si } b_i < 0\\
    \end{cases}.
\end{gather*}
Por lo tanto, la verosimilitud de las observaciones se puede calcular como
\begin{gather*}
    P(y | f_p(X),\sigma,b) \\
    \propto exp \left\{
        -\sum_{\{i|b_i > 0\}} \frac{p}{\sigma_i}(y_i-f_p(x_i)) -
        \sum_{\{i|b_i < 0\}} -\frac{1-p}{\sigma_i}(y_i-f_p(x_i))
    \right\} \\
    \prod_{\{i|b_i > 0\}}\mathds{1}_{\{y_i \geq f(x_i)\}}
    \prod_{\{i|b_i < 0\}}\mathds{1}_{\{y_i < f(x_i)\}}\\
    = exp \left\{
        -\sum_{\{i|b_i > 0\}} b_i(y_i-f_p(x_i)) -
        \sum_{\{i|b_i < 0\}} b_i(y_i-f_p(x_i))
    \right\} \\
    \prod_{\{i|b_i > 0\}}\mathds{1}_{\{y_i \geq f(x_i)\}}
    \prod_{\{i|b_i < 0\}}\mathds{1}_{\{y_i < f(x_i)\}}\\
    = exp \left\{-b^T(y-f_p(X))
    \right\}
    \prod_{\{i|b_i > 0\}}\mathds{1}_{\{y_i \geq f(x_i)\}}
    \prod_{\{i|b_i < 0\}}\mathds{1}_{\{y_i < f(x_i)\}}.\\
\end{gather*}
En esta peculiar verosimilitud, cada $f_p(x_i)$ estar\'a condicionada de manera excluyente a estar por arriba o por abajo de $y_i$. Por ese motivo, al multiplicar la verosimilitud por la distribuci\'on inicial Gaussiana de $f_p(X)$, se obtendr\'a como distribuci\'on posterior una Normal Truncada, misma que se detalla a continuaci\'on.
\begin{equation*}
\begin{aligned}
   f_p(X)|Y,X,M,b,\lambda &\sim TruncNormal(\bar{M}(X,b), K(X,X|\lambda), \gamma, \eta), \\
   \bar{M}(X,b) &= M(X) + K(X,X|\lambda)b, \\
   \gamma_i &= 
   \begin{cases}
    -\infty & \text{si }b_i > 0 \\
    y_i & \text{si }b_i < 0
   \end{cases},\\
   \eta_i &= 
   \begin{cases}
    y_i & \text{si }b_i > 0 \\
    \infty & \text{si }b_i < 0
   \end{cases},
\end{aligned}
\end{equation*}
donde $\gamma$ es el vector de l\'imites inferiores y $\eta$ es el vector de l\'imites superiores de la distribuci\'on Normal truncada.

Debido a que $f_p(X)$ se encuentra en la verosimilitud  \'unicamente como un elemento de primer orden, al hacer la multiplicaci\'on con la distribuci\'on inicial Normal, la varianza queda exactamente igual. La actualizaci\'on se da \'unicamente en la media, como una perturbaci\'on de la media inicial, dada por las covarianzas que tiene cada observaci\'on respecto a las dem\'as, as\'i como el signo de $b_i$ para cada una.

\subsubsection{Actualizaci\'on del par\'ametro de escala}

Condicional a los dem\'as valores obtenidos, se obtiene la distribuci\'on posterior  de $\lambda$ como
\begin{equation*}
\begin{gathered}
   P(\lambda|X,M(X),f_p(X),b,c_\lambda,d_\lambda) 
   \propto
   \lambda^{-\bar{c}_\lambda-1}
   \cdot
   exp\left\{- \frac{\bar{d}_\lambda}{\lambda}\right\}
   \cdot
   exp\left\{-\bar{B} \lambda\right\}, \\
   \bar{c}_\lambda = c_\lambda + \frac{p}{2}, \\
   \bar{d}_\lambda = d_\lambda + \bar{F}, \\
   \bar{F} = \frac{1}{2}(f_p(X)-M(X))^T [K(X,X|\lambda=1)^{-1}] (f_p(X)-M(X)), \\
   \bar{B} = \frac{1}{2}b^T [K(X,X|\lambda=1)] b.
\end{gathered}
\end{equation*}

\section{Predicci\'on}

Una de las desventajas de los modelos no param\'etricos es que, a diferencia de los modelos param\'etricos, es complicado interpretar los resultados del ajuste del modelo. Por ello, resulta particularmente importante la faceta de la predicci\'on, que es donde m\'as se puede explotar la flexibilidad de los modelos no param\'etricos, debido a que el objetivo es tener precisi\'on en la estimaci\'on. Espec\'ificamente esta secci\'on se enfocar\'a en la predicci\'on de $f_p$, que es el par\'ametro de mayor inter\'es del modelo.

Debido al uso del simulador de Gibbs, despu\'es de realizar el ajuste se cuenta con un conjunto grande de realizaciones aproximadas de $f_p(X)$, provenientes de las cadenas de Markov.

Recordando lo visto en la secci\'on 4.2.4, cuando se tienen valores de $f_p(X)$, es posible usar la propiedad de la \textit{Normal condicional} para realizar predicci\'on. Sea $X \in \mathbb{R}^m \times \mathbb{R}^n$ la matriz de datos originales, $X_* \in \mathbb{R}^r \times \mathbb{R}^n$ la matriz de datos a predecir, $f_p(X)$ una realizaci\'on de la distribuci\'on posterior correspondiente a X, y $f_p(X_*)$ el vector aleatorio de los datos a predecir. Se tiene entonces que 
\begin{equation*}
    f_p(X_*)|f_p(X) 
    \sim \mathcal{N}
    (\bar{M}(X,X_*),\bar{K}(X,X_*|\lambda)),
\end{equation*}
con
\begin{equation*}
\begin{aligned}
    \bar{M}(X,X_*) &= M(X_*) + K(X_*,X)K(X,X)^{-1}(f_p(X) - M(X)), \\
    \bar{K}(X,X_*|\lambda) &= 
    \lambda
    \times
    \left[
    K(X_*,X_*) -
    K(X_*,X)K(X,X)^{-1}K(X,X_*)
    \right]
    .
\end{aligned}
\end{equation*}
donde $K(X_1,X_2) = K(X_1,X_2|\lambda=1)$, y $X_1$ y $X_2$ pueden ser $X$ o $X_*$.

Por lo antes descrito, es posible obtener una realizaci\'on de $f_p(X_*)$ simulando de dicha distribuci\'on Normal. De esta manera, por cada valor de $f_p(X)$ y $\lambda$ en la cadena de Markov, se simula una realizaci\'on de $f_p(X_*)$, y entonces es posible aproximar la distribuci\'on posterior de $q_p(y|x)$, para los datos $X_*$.

\section{Hiper-par\'ametros iniciales del modelo}

Una complicaci\'on que puede tener un modelo jer\'arquico, como el GPDP, es que es complicado darle una interpretaci\'on intuitiva a los hiper-par\'ametros de las diversas capas, de forma que el conocimiento previo del modelador pueda reflejarse en valores asignados a ellos.

Para mitigar este problema, a continuaci\'on se proponen una serie de heur\'isticas para definirlos, mismas que se derivan de algunas ideas que me parecen sensatas, pero no se originan de ning\'un cuerpo axiom\'atico y bien podr\'ian ser mejoradas. Tambi\'en es importante aclarar que por lo comentado al inicio de la secci\'on 5.2, para todas ellas se pensar\'a que los datos est\'an estandarizados.

\subsection{Funci\'on de medias $m$}

Este es el hiper-par\'ametro al que se le puede dar una mayor interpretaci\'on, debido a que representa el nivel donde el modelador estima que se encontrar\'a el cuantil p-\'esimo de $y$, para cada valor de las covariables $x$.

Para simplificar el proceso de definici\'on de la funci\'on de medias $m$, se puede partir de la hip\'otesis que es constante, y, por lo tanto, las variaciones son \'unicamente producto de la varianza de $\varepsilon_p$. Dada la estructura de probabilidad posterior, la media de $f_p$ podr\'a actualizarse si los datos brindan informaci\'on suficiente para suponer lo contrario. 

Una vez aceptada esta estructura, resta asignar el valor constante que tomar\'a. Si el modelador tiene una idea del nivel donde espera los datos, puede asignar la constante $c$. En caso de no tenerla, un valor que se suele usar en diversos contextos es el de $c=0$, de forma que
\begin{equation*}
\begin{aligned}
    m:\mathbb{R}^n &\rightarrow \mathbb{R}, \text{tal que }\\
    m&(x) = c.
\end{aligned}
\end{equation*}

\subsection{\textit{Gamma-Inversa}s de $\lambda$ y el Proceso de Dirichlet}

Tanto $c_\lambda$ y $d_\lambda$, como $c_{DP}$ y $d_{DP}$ son par\'ametros de distribuciones \textit{Gamma-Inversa}. Es oportuno recordar que si $U \sim \mathcal{GI}(c,d)$, entonces
\begin{equation*}
\begin{aligned}
    \mathbb{E}[U] &= \frac{d}{c-1}, \text{ } c>1,\\
    Var(U) &= \frac{d^2}{(c-1)^2(c-2)}, \text{ } c>2.
\end{aligned}
\end{equation*}

En este orden de ideas, si se elige $c = 2$, $Var(U)$ ser\'a infinita y $\mathbb{E}[U] = d$. Asignar a $c_\lambda$ y $c_{DP}$ de esta manera permitir\'a darle a $d_\lambda$ y $d_{DP}$ el valor que se piense como el mejor estimador puntual \textit{a priori} de $\lambda$ y $\sigma$, pero con una varianza tal que permitir\'a a los datos tener el peso principal en la actualizaci\'on del modelo. 

Debido a la estandarizaci\'on de los datos, la varianza muestral de $y$ es igual a 1. Es posible pensarla como el resultado de sumar la varianza de $f_p(x)$ y la de $\varepsilon_p$, que adem\'as se suponen independientes. Entonces, se puede definir una heur\'istica tal que $Var(f_p(x)) = \frac{1}{2}$ y $Var(\varepsilon_p) = \frac{1}{2}$, a falta de mayor informaci\'on.

La varianza de $f_p(x)$ es igual a $\lambda$, por lo que lo coherente con lo dicho en los p\'arrafos anteriores ser\'a asignar $d_\lambda = \frac{1}{2}$. 

Por el otro lado, si \'unicamente para este ejercicio, y con el af\'an de volver an\'alitico el c\'alculo, se piensa a $\varepsilon_p \sim AL_p(\sigma = d_{DP})$. Entonces, su varianza estar\'ia dada por
\begin{equation*}
    Var(\varepsilon_p) = 
    \left[\frac{d_{DP}}{p(1-p)}\right]^2
    (1-2p(1-p)).
\end{equation*}
Dado que se fijar\'a $Var(\varepsilon_p) = \frac{1}{2}$, por la heur\'istica antes mencionada, despejando es posible obtener que
\begin{equation*}
    d_{DP} = \frac{p(1-p)}{\sqrt{2(1-2p(1-p))}}.
\end{equation*}

\subsection{Par\'ametro de concentraci\'on $\alpha$}

Este es el par\'ametro m\'as dif\'icil de definir, por su complejidad de interpretaci\'on. Pero cabe recordar que el valor de $\alpha$ tiene una relaci\'on positiva con el n\'umero de subpoblaciones. 

De hecho, sea $\bar{m}$ el n\'umero de subpoblaciones y $m$ el n\'umero de datos de entrenamiento, \cite{Yee_DirProc} expone que
\begin{equation*}
    \mathbb{E}[\bar{m}|\alpha, m] 
    \simeq 
    \alpha
    \log 
    \left(
        1 + \frac{m}{\alpha}
    \right)
    \text{, para } m, \alpha \gg 0.
\end{equation*}

Si se define $\alpha = \frac{\sqrt{m}}{2}$, se tiene que
\begin{equation*}
\begin{aligned}
    \mathbb{E}[\bar{m}|m] 
    &\simeq 
    \frac{\sqrt{m}}{2}
    \times
    \log 
    \left(
        1 + 2\sqrt{m}
    \right)\\
    &\simeq
    \frac{m}{7} 
    \text{, para } m \approx 100.
\end{aligned}
\end{equation*}

Es decir, si se tienen alrededor de 100 observaciones, el n\'umero esperado de subpoblaciones ser\'a alrededor de la s\'eptima parte de las observaciones. Valor que a falta de mayor exploraci\'on en este tema, no suena descabellado. De nuevo, a mayor cantidad de datos, se tendr\'a una menor dependencia de esta arbitraria decisi\'on inicial.

\section{Consideraciones sobre la bondad de ajuste}

El modelo GPDP descrito en este trabajo pretende ser una opci\'on m\'as de modelo de regresi\'on, particularmente \'util cuando es inter\'es del modelador aproximar alg\'un cuantil en espec\'ifico de la variable de respuesta, dados los valores de las variables explicativas.

Sin embargo, no est\'a de m\'as recordar que existen muchos otros modelos de regresi\'on, a la media y sobre cuantiles, lineales y no lineales, param\'etricos y no param\'etricos. Todos ellos cumplen el mismo cometido de estimar la distribuci\'on condicional de $y|x$.

En la siguiente secci\'on se har\'a un an\'alisis de los resultados obtenidos por el modelo GPDP, que har\'a uso de herramientas b\'asicas, como la exploraci\'on visual o la correlaci\'on. En este sentido, hay una evidente \'area de mejora, ya que se podr\'ia encontrar alguna medida robusta, estad\'isticamente hablando, de bondad de ajuste. \'Esta permitir\'ia saber qu\'e tan bueno resulta el modelo para describir un conjunto dado de datos, y permitir\'ia compararlo con otros, para seleccionar cu\'al es el que presenta mejores resultados. 

Desafortunadamente, realizar esto con un modelo con la estructura del GPDP resulta complejo y la literatura para medir la bondad de ajuste de modelos de regresi\'on bayesianos, sobre cuantiles y no parame\'etricos, est\'a apenas en sus pininos. Por lo tanto, una estimaci\'on robusta de la bondad de ajuste del modelo GPDP y la selecci\'on del mejor modelo quedan fuera del alcance de este trabajo.


\section{Paquete \textit{GPDPQuantReg} en R}

Todas las ideas expuestas en este cap\'itulo han sido implementadas en el paquete \textit{GPDPQuantReg} del lenguaje de programaci\'on R, mismo que puede ser encontrado en el repositorio de Github\faGithub \space titulado: \textbf{opardo/GPDPQuantReg}.

Al momento de escribir este trabajo, cuenta con tres funciones p\'ublicas: \textit{GPDPQuantReg}, para ajustar el modelo con el simulador de Gibbs; \textit{predict}, para realizar predicci\'on en un nuevo conjunto de datos del modelo ajustado; y \textit{diagnose}, para realizar el diagn\'ostico de la ergodicidad, la autocorrelaci\'on, la correlaci\'on cruzada y la traza de las cadenas de Markov, para los distintos par\'ametros.

A continuaci\'on se expone un ejemplo de uso, el cual es similar a lo que se realiz\'o para obtener los resultados del cap\'itulo siguiente.

\lstinputlisting{R/package_example.R}

\newpage