\chapter[Conclusiones y trabajo futuro]{Conclusiones y trabajo futuro}

Si bien los modelos de regresi\'on a la media han sido de mucha utilidad en las \'ultimas d\'ecadas, principalmente cuando el poder computacional era menor, es importante darse cuenta que actualmente existen contextos en los que resultan insuficientes. Ya sea porque sea desea la mejor aproximaci\'on posible de alg\'un estad\'istico distinto a la media, o debido a que hay ocasiones en las que no se cumplen algunos de sus supuestos.

De manera similar, la relaci\'on lineal en los par\'ametros y la distribuci\'on Normal del error han sido fundamentales para que los modelos de regresi\'on hayan proliferado en una gran cantidad de industrias, tanto por su interpretabilidad, como por su bajo costo de estimaci\'on. Sin embargo, es imposible ignorar que \'unicamente representan un subconjunto del universo de funciones y errores aleatorios posibles. Crear modelos que permitan una mayor flexibilidad, como aquellos que utilizan m\'etodos no param\'etricos, lograr\'a una representaci\'on m\'as certera de la realidad de la que provienen los datos.

Al momento de hacer aproximaciones estad\'isticas, se dice que utilizar el paradigma Bayesiano muchas veces presenta la ventaja de poder introducir el conocimiento previo de las personas expertas en el fen\'omeno a estudiar. Desafortunadamente, en un modelo jer\'arquico, como lo es el expuesto en esta tesis, es complicado transmitir dicho conocimiento. Principalmente, debido a que los hiper-par\'ametros se encuentran varias capas abajo de aquellos par\'ametros que tienen una interpretaci\'on natural. A pesar de ello, vale la pena resaltar que dicha construcci\'on jer\'arquica, con la flexibilidad que brinda, es posible y es congruente gracias al paradigma Bayesiano, debido a que todas las expresiones son completamente probabil\'isticas y fundadas en un cuerpo axiom\'atico. 

Un reto importante que present\'o este trabajo fue el desarrollo del paquete en R para implementar el modelo GPDP. Primero, porque se requiri\'o plantear te\'oricamente la distribuciones condicionales necesarias para que corriera el simulador de Gibbs. Y segundo, porque tuve que buscar programar de forma general y eficiente, para que el paquete funcionara siempre que recibiera los par\'ametros predefinidos, y corriera lo m\'as r\'apido posible, ante la desventaja que representa s\'olo poder calcular a la vez una iteraci\'on de la cadena de Markov. De hecho, dej\'e el n\'umero de iteraciones como un par\'ametro a elecci\'on del modelador, para que pueda decidir si prefiere precisi\'on o velocidad.

Si bien estos avances son significativos, a\'un existe mucho que explorar respecto a lo expuesto en esta tesis. Por ejemplo, el modelo planteado en este trabajo no es capaz de darle un peso distinto a cada variable explicativa, sino que las toma  a todas por igual al momento de calcular la distancia entre observaciones. Para mejorar esta situaci\'on se podr\'ia plantear una descomposici\'on de la funci\'on del cuantil en la suma de varios procesos Gaussianos, uno por covariable, lo que brindar\'ia un mayor peso a aquellas que en efecto sean m\'as significativas para explicar el fen\'omeno en cuesti\'on. 

Adem\'as, ser\'ia conveniente la inclusi\'on de un par\'ametro de rango que regule din\'amicamente la relaci\'on entre la distancia y la covarianza entre observaciones. Por ejemplo, a\'un cuando est\'en estandarizados los datos, una misma distancia podr\'ia significar una covarianza grande entre observaciones para alguna covariable o fen\'omeno, pero covarianza casi nula para otro. Lograr implementar este par\'ametro din\'amico seguramente mejorar\'a el ajuste.

Finalmente, tendr\'ia una gran utilidad el desarrollar una medida robusta de bondad de ajuste para este tipo de modelos. Esto brindar\'ia cualidades importantes al modelo GPDP, como el poder hacer selecci\'on de variables, y tambi\'en permitir\'ia saber qu\'e tan bueno o malo es el modelo, en comparaci\'on con lo dem\'as disponibles. 

\newpage 